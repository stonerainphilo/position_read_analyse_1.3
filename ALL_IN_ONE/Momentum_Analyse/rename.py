import numpy as np
import pandas as pd
import h5py
import json
import matplotlib.pyplot as plt
from pathlib import Path
from scipy import stats
import seaborn as sns
from typing import Dict, List, Tuple, Optional, Any
from tqdm import tqdm
import warnings
warnings.filterwarnings('ignore')
import pickle

class LLPDistributionAnalyzer:
    """
    LLPè¡°å˜ä½ç½®åˆ†å¸ƒåˆ†æå™¨
    ä¸“é—¨å¤„ç†æ‚¨çš„æ•°æ®ç»“æ„
    """
    
    def __init__(self, data_dir: str):
        self.data_dir = Path(data_dir)
        self.llp_data = {}
        self.distribution_models = {}
        self.summary_df = None
        
    def load_all_data(self):
        """åŠ è½½æ‰€æœ‰LLPæ•°æ®"""
        print("=" * 70)
        print("LOADING LLP DATA")
        print("=" * 70)
        
        # æŸ¥æ‰¾æ‰€æœ‰llpç›®å½•
        llp_dirs = sorted(list(self.data_dir.glob("llp_*_temp")))
        print(f"Found {len(llp_dirs)} LLP directories")
        
        for llp_dir in tqdm(llp_dirs, desc="Loading data"):
            llp_id = llp_dir.stem.replace('_temp', '')
            
            try:
                # ä»blocksç›®å½•åŠ è½½æ•°æ®
                data = self._load_llp_data(llp_dir, llp_id)
                if data:
                    self.llp_data[llp_id] = data
                    
            except Exception as e:
                print(f"\nWarning: Failed to load {llp_id}: {e}")
        
        if not self.llp_data:
            raise ValueError("No data loaded!")
        
        print(f"\nSuccessfully loaded {len(self.llp_data)} LLP datasets")
        self._create_summary_dataframe()
    
    def _load_llp_data(self, llp_dir: Path, llp_id: str) -> Optional[Dict]:
        """åŠ è½½å•ä¸ªLLPçš„æ•°æ®"""
        blocks_dir = llp_dir / "blocks"
        if not blocks_dir.exists():
            return None
        
        # æŸ¥æ‰¾blockå­ç›®å½•
        block_dirs = [d for d in blocks_dir.iterdir() if d.is_dir()]
        if not block_dirs:
            return None
        
        # åŠ è½½ç¬¬ä¸€ä¸ªblockï¼ˆé€šå¸¸åªæœ‰ä¸€ä¸ªï¼‰
        block_dir = block_dirs[0]
        h5_file = block_dir / "data.h5"
        
        if not h5_file.exists():
            return None
        
        # è¯»å–HDF5æ–‡ä»¶
        with h5py.File(h5_file, 'r') as f:
            # è¯»å–ä½ç½®æ•°æ®
            positions = f['positions'][:]
            
            # è¯»å–æƒé‡
            weights = f['weights'][:]
            
            # è¯»å–å‚æ•°
            params_group = f['parameters']
            params = dict(params_group.attrs)
            
            # ç¡®ä¿å‚æ•°æ˜¯PythonåŸç”Ÿç±»å‹
            for key, value in params.items():
                if hasattr(value, 'item'):  # numpyç±»å‹
                    params[key] = value.item()
        
        return {
            'llp_id': llp_id,
            'positions': positions,
            'weights': weights,
            'params': params,
            'n_samples': len(positions),
            'total_weight': float(np.sum(weights))
        }
    
    def _create_summary_dataframe(self):
        """åˆ›å»ºæ‘˜è¦DataFrame"""
        summary_data = []
        
        for llp_id, data in self.llp_data.items():
            params = data['params']
            
            summary = {
                'llp_id': llp_id,
                'mass': float(params.get('mass', np.nan)),
                'lifetime': float(params.get('lifetime', np.nan)),
                'tanb': float(params.get('tanb', np.nan)),
                'vis_br': float(params.get('vis_br', np.nan)),
                'n_samples': data['n_samples'],
                'total_weight': data['total_weight']
            }
            
            # æ·»åŠ ä½ç½®ç»Ÿè®¡
            positions = data['positions']
            for idx, coord in enumerate(['x', 'y', 'z']):
                coord_data = positions[:, idx]
                weights = data['weights']
                
                weighted_mean = np.average(coord_data, weights=weights)
                weighted_std = np.sqrt(np.average((coord_data - weighted_mean)**2, weights=weights))
                
                summary[f'{coord}_mean'] = float(weighted_mean)
                summary[f'{coord}_std'] = float(weighted_std)
                summary[f'{coord}_min'] = float(np.min(coord_data))
                summary[f'{coord}_max'] = float(np.max(coord_data))
            
            summary_data.append(summary)
        
        self.summary_df = pd.DataFrame(summary_data)
        
        print(f"\nDATA SUMMARY:")
        print("-" * 40)
        print(f"Total LLP parameter sets: {len(self.summary_df)}")
        print(f"Total positions: {self.summary_df['n_samples'].sum():,}")
        print(f"Mass range: {self.summary_df['mass'].min():.3f} - {self.summary_df['mass'].max():.3f} GeV")
        print(f"Lifetime range: {self.summary_df['lifetime'].min():.2e} - {self.summary_df['lifetime'].max():.2e} mm")
        print(f"tanÎ² range: {self.summary_df['tanb'].min():.2f} - {self.summary_df['tanb'].max():.2f}")
        
        print(f"\nFirst 3 LLPs:")
        for i, row in self.summary_df.head(3).iterrows():
            print(f"  {row['llp_id']}: m={row['mass']:.3f}GeV, Ï„={row['lifetime']:.2e}mm, tanÎ²={row['tanb']:.1f}")
    
    def _get_formatted_filename(self, params: Dict, suffix: str = "") -> str:
        """
        æ ¹æ®å‚æ•°ç”Ÿæˆæ ¼å¼åŒ–æ–‡ä»¶å
        
        æ ¼å¼: m_{è´¨é‡}_tau_{å¯¿å‘½}_{åç¼€}
        
        å‚æ•°:
        - params: åŒ…å«masså’Œlifetimeçš„å­—å…¸
        - suffix: æ–‡ä»¶ååç¼€
        
        è¿”å›:
        - æ ¼å¼åŒ–åçš„æ–‡ä»¶å
        """
        mass = float(params.get('mass', 0))
        lifetime = float(params.get('lifetime', 0))
        
        # æ ¼å¼åŒ–è´¨é‡ï¼ˆä¿ç•™3ä½å°æ•°ï¼‰
        mass_str = f"{mass:.3f}"
        
        # æ ¼å¼åŒ–å¯¿å‘½
        if lifetime < 0.01 or lifetime > 1000:
            # ä½¿ç”¨ç§‘å­¦è®¡æ•°æ³•
            lifetime_str = f"{lifetime:.2e}"
        else:
            # ä½¿ç”¨å¸¸è§„æ ¼å¼
            lifetime_str = f"{lifetime:.2f}"
        
        # æ¸…ç†ç§‘å­¦è®¡æ•°æ³•æ ¼å¼
        lifetime_str = lifetime_str.replace('e+0', 'e').replace('e-0', 'e')
        lifetime_str = lifetime_str.replace('e+', 'e').replace('e-', 'e')
        lifetime_str = lifetime_str.replace('+', '')
        
        # æ„å»ºæ–‡ä»¶å
        filename = f"m_{mass_str}_tau_{lifetime_str}"
        if suffix:
            filename = f"{filename}_{suffix}"
        
        return filename
    
    def analyze_distributions(self):
        """ä¸ºæ¯ä¸ªLLPåˆ†æè¡°å˜ä½ç½®åˆ†å¸ƒ"""
        print(f"\n{'='*70}")
        print("ANALYZING DISTRIBUTIONS")
        print('='*70)
        
        for llp_id, data in tqdm(self.llp_data.items(), desc="Analyzing distributions"):
            try:
                distribution_model = self._analyze_llp_distribution(llp_id, data)
                if distribution_model:
                    self.distribution_models[llp_id] = distribution_model
            except Exception as e:
                print(f"\nWarning: Failed to analyze {llp_id}: {e}")
        
        print(f"\nSuccessfully analyzed distributions for {len(self.distribution_models)} LLPs")
    
    def _analyze_llp_distribution(self, llp_id: str, data: Dict) -> Dict:
        """åˆ†æå•ä¸ªLLPçš„åˆ†å¸ƒ"""
        positions = data['positions']
        weights = data['weights']
        params = data['params']
        
        # åˆ†ææ¯ä¸ªåæ ‡çš„åˆ†å¸ƒ
        coord_models = {}
        
        for idx, coord in enumerate(['x', 'y', 'z']):
            coord_data = positions[:, idx]
            
            # è®¡ç®—åŠ æƒç»Ÿè®¡
            weighted_mean = np.average(coord_data, weights=weights)
            weighted_std = np.sqrt(np.average((coord_data - weighted_mean)**2, weights=weights))
            
            # åˆ›å»ºæ ¸å¯†åº¦ä¼°è®¡
            from scipy.stats import gaussian_kde
            weights_norm = weights / np.sum(weights)
            kde = gaussian_kde(coord_data, weights=weights_norm)
            
            # è®¡ç®—ç™¾åˆ†ä½æ•°
            percentiles = {
                'p5': float(np.percentile(coord_data, 5)),
                'p25': float(np.percentile(coord_data, 25)),
                'p50': float(np.percentile(coord_data, 50)),
                'p75': float(np.percentile(coord_data, 75)),
                'p95': float(np.percentile(coord_data, 95))
            }
            
            # åˆ›å»ºåˆ†å¸ƒå‡½æ•°
            def pdf_func(x, use_kde=True):
                if use_kde:
                    return kde(x)
                else:
                    # é«˜æ–¯è¿‘ä¼¼
                    return stats.norm.pdf(x, loc=weighted_mean, scale=weighted_std)
            
            def cdf_func(x):
                # ç»éªŒCDF
                sorted_data = np.sort(coord_data)
                ecdf = np.searchsorted(sorted_data, x, side='right') / len(coord_data)
                return ecdf
            
            def rvs_func(size=1):
                # ä»ç»éªŒåˆ†å¸ƒé‡‡æ ·
                indices = np.random.choice(len(coord_data), size=size, p=weights_norm)
                return coord_data[indices]
            
            coord_models[coord] = {
                'mean': float(weighted_mean),
                'std': float(weighted_std),
                'min': float(np.min(coord_data)),
                'max': float(np.max(coord_data)),
                'percentiles': percentiles,
                'kde': kde,
                'pdf': pdf_func,
                'cdf': cdf_func,
                'rvs': rvs_func
            }
        
        return {
            'llp_id': llp_id,
            'params': params,
            'models': coord_models,
            'n_samples': data['n_samples'],
            'total_weight': data['total_weight'],
            'formatted_name': self._get_formatted_filename(params)
        }
    
    def create_distribution_plots(self, output_dir: str = './llp_distributions'):
        """åˆ›å»ºåˆ†å¸ƒå›¾ï¼Œä½¿ç”¨æ–°å‘½åæ ¼å¼"""
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        
        print(f"\nCreating distribution plots in {output_path}...")
        
        # ä¸ºæ¯ä¸ªLLPåˆ›å»ºå›¾
        for llp_id, dist_model in tqdm(self.distribution_models.items(), 
                                      desc="Creating plots"):
            try:
                self._create_llp_distribution_plot(llp_id, dist_model, output_path)
            except Exception as e:
                print(f"\nWarning: Failed to create plot for {llp_id}: {e}")
        
        # åˆ›å»ºæ¯”è¾ƒå›¾
        self._create_comparison_plots(output_path)
        
        print(f"\nâœ“ All plots saved to {output_path}")
    
    def _create_llp_distribution_plot(self, llp_id: str, dist_model: Dict, output_path: Path):
        """åˆ›å»ºå•ä¸ªLLPçš„åˆ†å¸ƒå›¾ï¼Œä½¿ç”¨æ–°å‘½åæ ¼å¼"""
        params = dist_model['params']
        formatted_name = dist_model.get('formatted_name', llp_id)
        
        # åˆ›å»ºæ ‡é¢˜
        title = f"LLP: {formatted_name}\n"
        title += f"Mass: {params.get('mass', 'N/A'):.3f} GeV, "
        title += f"Ï„: {params.get('lifetime', 'N/A'):.2e} mm, "
        title += f"tanÎ²: {params.get('tanb', 'N/A'):.1f}"
        
        # åˆ›å»º2x3çš„å­å›¾
        fig, axes = plt.subplots(2, 3, figsize=(15, 10))
        fig.suptitle(title, fontsize=14, y=1.02)
        
        # ç¬¬ä¸€è¡Œï¼šPDFå›¾
        for idx, coord in enumerate(['x', 'y', 'z']):
            ax = axes[0, idx]
            model = dist_model['models'][coord]
            
            # ç”ŸæˆxèŒƒå›´
            x_min, x_max = model['min'], model['max']
            x_range = np.linspace(x_min, x_max, 1000)
            
            # ç»˜åˆ¶KDE PDF
            pdf_kde = model['pdf'](x_range, use_kde=True)
            ax.plot(x_range, pdf_kde, 'r-', linewidth=2, label='KDE PDF')
            
            # ç»˜åˆ¶é«˜æ–¯è¿‘ä¼¼
            pdf_gauss = model['pdf'](x_range, use_kde=False)
            ax.plot(x_range, pdf_gauss, 'b--', linewidth=1.5, alpha=0.7, label='Gaussian')
            
            # æ·»åŠ å‡å€¼å’Œæ ‡å‡†å·®çº¿
            mean = model['mean']
            std = model['std']
            
            ax.axvline(mean, color='g', linestyle='-', alpha=0.5, label=f'Mean: {mean:.1f}')
            ax.axvline(mean - std, color='g', linestyle=':', alpha=0.5)
            ax.axvline(mean + std, color='g', linestyle=':', alpha=0.5, label=f'Std: Â±{std:.1f}')
            
            ax.set_xlabel(f'{coord.upper()} Position (mm)', fontsize=11)
            ax.set_ylabel('Probability Density', fontsize=11)
            ax.set_title(f'{coord.upper()} Distribution', fontsize=12)
            ax.legend(fontsize=9, loc='upper right')
            ax.grid(True, alpha=0.3)
        
        # ç¬¬äºŒè¡Œï¼šCDFå’Œç®±çº¿å›¾
        for idx, coord in enumerate(['x', 'y', 'z']):
            ax = axes[1, idx]
            model = dist_model['models'][coord]
            
            # ç»˜åˆ¶CDF
            x_min, x_max = model['min'], model['max']
            x_range = np.linspace(x_min, x_max, 1000)
            cdf_vals = model['cdf'](x_range)
            
            ax.plot(x_range, cdf_vals, 'b-', linewidth=2, label='Empirical CDF')
            
            # æ·»åŠ ç™¾åˆ†ä½æ•°æ ‡è®°
            percentiles = model['percentiles']
            p_labels = ['5%', '25%', '50%', '75%', '95%']
            colors = ['r', 'orange', 'g', 'orange', 'r']
            
            for (key, value), label, color in zip(percentiles.items(), p_labels, colors):
                ax.axvline(value, color=color, linestyle='--', alpha=0.5)
                cdf_value = model['cdf'](np.array([value]))[0]
                ax.plot(value, cdf_value, 'o', color=color, markersize=5)
                ax.text(value, cdf_value + 0.05, label, 
                       ha='center', fontsize=9, color=color)
            
            ax.set_xlabel(f'{coord.upper()} Position (mm)', fontsize=11)
            ax.set_ylabel('Cumulative Probability', fontsize=11)
            ax.set_title(f'{coord.upper()} CDF with Percentiles', fontsize=12)
            ax.legend(fontsize=9)
            ax.grid(True, alpha=0.3)
            ax.set_ylim([0, 1])
        
        plt.tight_layout()
        
        # ä½¿ç”¨æ–°å‘½åæ ¼å¼ä¿å­˜æ–‡ä»¶
        plot_filename = f"{formatted_name}_distribution.png"
        plt.savefig(output_path / plot_filename, dpi=150, bbox_inches='tight')
        plt.close()
        
        # åˆ›å»º3Dæ•£ç‚¹å›¾
        fig = plt.figure(figsize=(10, 8))
        ax = fig.add_subplot(111, projection='3d')
        
        # è·å–åŸå§‹æ•°æ®
        positions = self.llp_data[llp_id]['positions']
        
        # æŠ½æ ·æ˜¾ç¤ºï¼ˆé¿å…å¤ªå¤šç‚¹ï¼‰
        if len(positions) > 5000:
            sample_idx = np.random.choice(len(positions), 5000, replace=False)
            plot_pos = positions[sample_idx]
        else:
            plot_pos = positions
        
        # ä½¿ç”¨é¢œè‰²è¡¨ç¤ºæƒé‡
        weights = self.llp_data[llp_id]['weights']
        if len(weights) > 5000:
            plot_weights = weights[sample_idx]
        else:
            plot_weights = weights
        
        scatter = ax.scatter(plot_pos[:, 0], plot_pos[:, 1], plot_pos[:, 2],
                           c=plot_weights, cmap='viridis', alpha=0.3, s=1)
        
        # æ·»åŠ å‡å€¼ç‚¹
        x_mean = dist_model['models']['x']['mean']
        y_mean = dist_model['models']['y']['mean']
        z_mean = dist_model['models']['z']['mean']
        
        ax.scatter([x_mean], [y_mean], [z_mean], c='red', s=100, marker='*', label='Mean')
        
        ax.set_xlabel('X (mm)', fontsize=11)
        ax.set_ylabel('Y (mm)', fontsize=11)
        ax.set_zlabel('Z (mm)', fontsize=11)
        ax.set_title(f'{formatted_name}: 3D Decay Positions', fontsize=12)
        ax.legend()
        
        plt.colorbar(scatter, ax=ax, label='Weight')
        plt.tight_layout()
        
        # ä½¿ç”¨æ–°å‘½åæ ¼å¼ä¿å­˜3Då›¾
        plot_3d_filename = f"{formatted_name}_3d_positions.png"
        plt.savefig(output_path / plot_3d_filename, dpi=150, bbox_inches='tight')
        plt.close()
    
    def _create_comparison_plots(self, output_path: Path):
        """åˆ›å»ºLLPä¹‹é—´çš„æ¯”è¾ƒå›¾"""
        if len(self.distribution_models) < 2:
            return
        
        print("\nCreating comparison plots...")
        
        # 1. åˆ†å¸ƒç»Ÿè®¡éšå‚æ•°çš„å˜åŒ–
        fig, axes = plt.subplots(2, 3, figsize=(15, 10))
        
        for row_idx, param in enumerate(['mass', 'lifetime']):
            for col_idx, coord in enumerate(['x', 'y', 'z']):
                ax = axes[row_idx, col_idx]
                
                # æ”¶é›†æ•°æ®
                x_vals = []
                mean_vals = []
                std_vals = []
                labels = []
                
                for llp_id, dist_model in self.distribution_models.items():
                    if param in dist_model['params']:
                        x_vals.append(float(dist_model['params'][param]))
                        mean_vals.append(dist_model['models'][coord]['mean'])
                        std_vals.append(dist_model['models'][coord]['std'])
                        labels.append(dist_model.get('formatted_name', llp_id))
                
                if len(x_vals) > 0:
                    # æ’åº
                    sort_idx = np.argsort(x_vals)
                    x_sorted = np.array(x_vals)[sort_idx]
                    mean_sorted = np.array(mean_vals)[sort_idx]
                    std_sorted = np.array(std_vals)[sort_idx]
                    labels_sorted = np.array(labels)[sort_idx]
                    
                    # åˆ›å»ºæ•£ç‚¹å›¾
                    scatter = ax.errorbar(x_sorted, mean_sorted, yerr=std_sorted,
                                        fmt='o', alpha=0.7, capsize=3, markersize=4)
                    
                    # å¯é€‰ï¼šæ·»åŠ æ ‡ç­¾ï¼ˆæ¯ç¬¬Nä¸ªç‚¹ï¼‰
                    if len(labels_sorted) <= 20:  # å¦‚æœç‚¹ä¸å¤šï¼Œå…¨éƒ¨æ ‡æ³¨
                        for i, label in enumerate(labels_sorted):
                            ax.annotate(label, (x_sorted[i], mean_sorted[i]), 
                                       fontsize=6, alpha=0.7)
                    
                    x_label = 'Mass (GeV)' if param == 'mass' else 'Lifetime (mm)'
                    if param == 'lifetime':
                        ax.set_xscale('log')
                    
                    ax.set_xlabel(x_label, fontsize=11)
                    ax.set_ylabel(f'{coord.upper()} Mean Â± Std (mm)', fontsize=11)
                    ax.set_title(f'{coord.upper()} vs {param.capitalize()}', fontsize=12)
                    ax.grid(True, alpha=0.3)
        
        plt.suptitle('Distribution Statistics vs LLP Parameters', fontsize=14, y=1.02)
        plt.tight_layout()
        
        # ä½¿ç”¨æ–°å‘½åæ ¼å¼ä¿å­˜æ¯”è¾ƒå›¾
        plt.savefig(output_path / 'parameter_comparison.png', dpi=150, bbox_inches='tight')
        plt.close()
        
        # 2. å‚æ•°ç©ºé—´çƒ­å›¾ï¼šåˆ†å¸ƒå®½åº¦
        fig, axes = plt.subplots(1, 3, figsize=(15, 5))
        
        for idx, (coord, cmap) in enumerate(zip(['x', 'y', 'z'], ['viridis', 'plasma', 'inferno'])):
            ax = axes[idx]
            
            x_vals = []
            y_vals = []
            z_vals = []
            labels = []
            
            for llp_id, dist_model in self.distribution_models.items():
                params = dist_model['params']
                if 'mass' in params and 'lifetime' in params:
                    x_vals.append(float(params['mass']))
                    y_vals.append(float(params['lifetime']))
                    z_vals.append(dist_model['models'][coord]['std'])
                    labels.append(dist_model.get('formatted_name', llp_id))
            
            if len(x_vals) > 0:
                scatter = ax.scatter(x_vals, np.log10(y_vals), c=z_vals,
                                   cmap=cmap, alpha=0.7, s=50)
                
                # æ·»åŠ æ ‡ç­¾ï¼ˆå¦‚æœç‚¹ä¸å¤šï¼‰
                if len(labels) <= 20:
                    for i, label in enumerate(labels):
                        ax.annotate(label, (x_vals[i], np.log10(y_vals[i])), 
                                   fontsize=6, alpha=0.7)
                
                ax.set_xlabel('Mass (GeV)', fontsize=11)
                ax.set_ylabel('log10(Lifetime) (mm)', fontsize=11)
                ax.set_title(f'{coord.upper()} Std Dev in Parameter Space', fontsize=12)
                ax.grid(True, alpha=0.3)
                
                plt.colorbar(scatter, ax=ax, label=f'{coord.upper()} Std Dev (mm)')
        
        plt.suptitle('Distribution Width Analysis', fontsize=14, y=1.02)
        plt.tight_layout()
        plt.savefig(output_path / 'std_dev_heatmaps.png', dpi=150, bbox_inches='tight')
        plt.close()
        
        # 3. ç»¼åˆæ€»ç»“å›¾
        fig = plt.figure(figsize=(16, 12))
        
        # åˆ›å»ºå¸ƒå±€
        gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)
        
        # å­å›¾1: å‚æ•°ç©ºé—´
        ax1 = fig.add_subplot(gs[0, 0])
        x_vals = []
        y_vals = []
        colors = []
        labels = []
        
        for llp_id, dist_model in self.distribution_models.items():
            params = dist_model['params']
            if 'mass' in params and 'lifetime' in params:
                x_vals.append(float(params['mass']))
                y_vals.append(float(params['lifetime']))
                colors.append(dist_model['total_weight'])
                labels.append(dist_model.get('formatted_name', llp_id))
        
        if x_vals:
            scatter1 = ax1.scatter(x_vals, np.log10(y_vals), c=colors, 
                                 cmap='viridis', alpha=0.7, s=50)
            
            # æ·»åŠ æ ‡ç­¾
            if len(labels) <= 30:
                for i, label in enumerate(labels):
                    ax1.annotate(label, (x_vals[i], np.log10(y_vals[i])), 
                               fontsize=5, alpha=0.7)
            
            ax1.set_xlabel('Mass (GeV)', fontsize=11)
            ax1.set_ylabel('log10(Lifetime) (mm)', fontsize=11)
            ax1.set_title('Parameter Space (colored by total weight)', fontsize=12)
            ax1.grid(True, alpha=0.3)
            plt.colorbar(scatter1, ax=ax1, label='Total Weight')
        
        # å­å›¾2: æ ·æœ¬æ•°é‡åˆ†å¸ƒ
        ax2 = fig.add_subplot(gs[0, 1])
        n_samples = [d['n_samples'] for d in self.llp_data.values()]
        ax2.hist(n_samples, bins=20, alpha=0.7, edgecolor='black')
        ax2.set_xlabel('Number of Positions', fontsize=11)
        ax2.set_ylabel('Frequency', fontsize=11)
        ax2.set_title('Distribution of Sample Sizes', fontsize=12)
        ax2.grid(True, alpha=0.3)
        
        # å­å›¾3: å¹³å‡ä½ç½®åˆ†å¸ƒ
        ax3 = fig.add_subplot(gs[0, 2])
        mean_positions = []
        for dist_model in self.distribution_models.values():
            for coord in ['x', 'y', 'z']:
                mean_positions.append(dist_model['models'][coord]['mean'])
        
        ax3.hist(mean_positions, bins=30, alpha=0.7, edgecolor='black')
        ax3.set_xlabel('Mean Position (mm)', fontsize=11)
        ax3.set_ylabel('Frequency', fontsize=11)
        ax3.set_title('Distribution of Mean Positions', fontsize=12)
        ax3.grid(True, alpha=0.3)
        
        # å­å›¾4-6: å„åæ ‡çš„æ ‡å‡†å·®åˆ†å¸ƒ
        for idx, coord in enumerate(['x', 'y', 'z']):
            ax = fig.add_subplot(gs[1, idx])
            std_vals = [dist_model['models'][coord]['std'] 
                       for dist_model in self.distribution_models.values()]
            
            ax.hist(std_vals, bins=20, alpha=0.7, edgecolor='black')
            ax.set_xlabel(f'{coord.upper()} Std Dev (mm)', fontsize=11)
            ax.set_ylabel('Frequency', fontsize=11)
            ax.set_title(f'{coord.upper()} Spread Distribution', fontsize=12)
            ax.grid(True, alpha=0.3)
        
        # å­å›¾7-9: ç›¸å…³ç³»æ•°
        ax7 = fig.add_subplot(gs[2, 0])
        # å‡†å¤‡ç›¸å…³æ•°æ®
        corr_data = []
        for dist_model in self.distribution_models.values():
            params = dist_model['params']
            models = dist_model['models']
            
            if 'mass' in params and 'lifetime' in params:
                row = {
                    'mass': float(params['mass']),
                    'log_lifetime': np.log10(float(params['lifetime'])),
                    'x_mean': models['x']['mean'],
                    'y_mean': models['y']['mean'],
                    'z_mean': models['z']['mean']
                }
                corr_data.append(row)
        
        if corr_data:
            corr_df = pd.DataFrame(corr_data)
            correlation = corr_df.corr()
            
            im = ax7.imshow(correlation, cmap='coolwarm', vmin=-1, vmax=1)
            ax7.set_xticks(range(len(correlation.columns)))
            ax7.set_xticklabels([col[:10] for col in correlation.columns], 
                              rotation=45, fontsize=9)
            ax7.set_yticks(range(len(correlation.columns)))
            ax7.set_yticklabels([col[:10] for col in correlation.columns], 
                              fontsize=9)
            ax7.set_title('Correlation Matrix', fontsize=12)
            plt.colorbar(im, ax=ax7)
        
        # å­å›¾8: å…³é”®ç»Ÿè®¡
        ax8 = fig.add_subplot(gs[2, 1])
        stats_text = [
            f"Total LLPs: {len(self.llp_data)}",
            f"Total positions: {self.summary_df['n_samples'].sum():,}",
            f"Mass range: {self.summary_df['mass'].min():.3f}-{self.summary_df['mass'].max():.3f} GeV",
            f"Lifetime range: {self.summary_df['lifetime'].min():.2e}-{self.summary_df['lifetime'].max():.2e} mm",
            f"tanÎ² range: {self.summary_df['tanb'].min():.2f}-{self.summary_df['tanb'].max():.2f}"
        ]
        
        ax8.text(0.1, 0.9, '\n'.join(stats_text), transform=ax8.transAxes,
                fontsize=10, verticalalignment='top',
                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))
        ax8.axis('off')
        ax8.set_title('Key Statistics', fontsize=12)
        
        # å­å›¾9: å‚æ•°åˆ†å¸ƒ
        ax9 = fig.add_subplot(gs[2, 2])
        if 'mass' in self.summary_df.columns and 'tanb' in self.summary_df.columns:
            mass_vals = []
            tanb_vals = []
            lifetime_vals = []
            labels = []
            
            for dist_model in self.distribution_models.values():
                params = dist_model['params']
                if 'mass' in params and 'tanb' in params and 'lifetime' in params:
                    mass_vals.append(float(params['mass']))
                    tanb_vals.append(float(params['tanb']))
                    lifetime_vals.append(np.log10(float(params['lifetime'])))
                    labels.append(dist_model.get('formatted_name', ''))
            
            if mass_vals:
                scatter9 = ax9.scatter(mass_vals, tanb_vals,
                                     c=lifetime_vals, 
                                     cmap='viridis', alpha=0.7, s=50)
                
                # æ·»åŠ æ ‡ç­¾
                if len(labels) <= 30:
                    for i, label in enumerate(labels):
                        ax9.annotate(label, (mass_vals[i], tanb_vals[i]), 
                                   fontsize=5, alpha=0.7)
                
                ax9.set_xlabel('Mass (GeV)', fontsize=11)
                ax9.set_ylabel('tanÎ²', fontsize=11)
                ax9.set_title('Mass vs tanÎ² (colored by log10(Ï„))', fontsize=12)
                ax9.grid(True, alpha=0.3)
                plt.colorbar(scatter9, ax=ax9, label='log10(Lifetime)')
        
        plt.suptitle('LLP Decay Position Analysis Summary', fontsize=16, y=1.02)
        plt.tight_layout()
        plt.savefig(output_path / 'analysis_summary.png', dpi=150, bbox_inches='tight')
        plt.close()
    
    def save_results(self, output_dir: str = './llp_distributions'):
        """ä¿å­˜ç»“æœï¼Œä½¿ç”¨æ–°å‘½åæ ¼å¼"""
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        
        print(f"\nSaving results to {output_path}...")
        
        # 1. ä¿å­˜æ‘˜è¦æ•°æ®
        if self.summary_df is not None:
            csv_path = output_path / 'llp_summary.csv'
            self.summary_df.to_csv(csv_path, index=False)
            print(f"âœ“ Summary saved to: {csv_path}")
        
        # 2. ä¿å­˜åˆ†å¸ƒæ¨¡å‹ï¼ˆä½¿ç”¨æ–°å‘½åæ ¼å¼ï¼‰
        if self.distribution_models:
            models_dir = output_path / 'distribution_models'
            models_dir.mkdir(exist_ok=True)
            
            for llp_id, dist_model in self.distribution_models.items():
                # åˆ›å»ºè½»é‡çº§ç‰ˆæœ¬ï¼ˆç§»é™¤å‡½æ•°å’ŒKDEå¯¹è±¡ï¼‰
                light_model = {
                    'llp_id': dist_model['llp_id'],
                    'formatted_name': dist_model.get('formatted_name', llp_id),
                    'params': dist_model['params'],
                    'n_samples': dist_model['n_samples'],
                    'total_weight': dist_model['total_weight'],
                    'model_stats': {}
                }
                
                for coord in ['x', 'y', 'z']:
                    model = dist_model['models'][coord]
                    light_model['model_stats'][coord] = {
                        'mean': model['mean'],
                        'std': model['std'],
                        'min': model['min'],
                        'max': model['max'],
                        'percentiles': model['percentiles']
                    }
                
                # è·å–æ ¼å¼åŒ–æ–‡ä»¶å
                formatted_name = dist_model.get('formatted_name', llp_id)
                
                # ä¿å­˜ä¸ºJSONï¼ˆä½¿ç”¨æ–°å‘½åæ ¼å¼ï¼‰
                model_file = models_dir / f'{formatted_name}.json'
                with open(model_file, 'w') as f:
                    json.dump(light_model, f, indent=2, default=str)
                
                print(f"âœ“ Model saved: {formatted_name}.json")
            
            print(f"\nâœ“ All distribution models saved to: {models_dir}/")
        
        # 3. ç”ŸæˆæŠ¥å‘Š
        self._generate_report(output_path)
        
        print(f"\nâœ“ All results saved to: {output_path}")
    
    def _generate_report(self, output_path: Path):
        """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
        report = []
        
        report.append("=" * 70)
        report.append("LLP DECAY POSITION DISTRIBUTION ANALYSIS REPORT")
        report.append("=" * 70)
        report.append(f"\nAnalysis Date: {pd.Timestamp.now()}")
        report.append(f"Total LLP datasets analyzed: {len(self.llp_data)}")
        
        if self.summary_df is not None:
            report.append(f"\nDATA SUMMARY:")
            report.append("-" * 40)
            report.append(f"Total positions: {self.summary_df['n_samples'].sum():,}")
            report.append(f"Total weighted events: {self.summary_df['total_weight'].sum():.0f}")
            report.append(f"Mass range: {self.summary_df['mass'].min():.3f} - {self.summary_df['mass'].max():.3f} GeV")
            report.append(f"Lifetime range: {self.summary_df['lifetime'].min():.2e} - {self.summary_df['lifetime'].max():.2e} mm")
            report.append(f"tanÎ² range: {self.summary_df['tanb'].min():.2f} - {self.summary_df['tanb'].max():.2f}")
            report.append(f"Visible BR range: {self.summary_df['vis_br'].min():.2e} - {self.summary_df['vis_br'].max():.2e}")
        
        # åˆ†å¸ƒç»Ÿè®¡
        report.append(f"\n\nDISTRIBUTION STATISTICS:")
        report.append("-" * 40)
        
        if self.distribution_models:
            for coord in ['x', 'y', 'z']:
                means = [model['models'][coord]['mean'] for model in self.distribution_models.values()]
                stds = [model['models'][coord]['std'] for model in self.distribution_models.values()]
                
                report.append(f"\n{coord.upper()} coordinate:")
                report.append(f"  Mean position: {np.mean(means):.1f} Â± {np.std(means):.1f} mm")
                report.append(f"  Average spread: {np.mean(stds):.1f} Â± {np.std(stds):.1f} mm")
                report.append(f"  Position range: [{np.min(means):.1f}, {np.max(means):.1f}] mm")
        
        # æ–‡ä»¶å‘½åä¿¡æ¯
        report.append(f"\n\nFILE NAMING CONVENTION:")
        report.append("-" * 40)
        report.append("All files are named using the format: m_{mass}_tau_{lifetime}")
        report.append("Example: m_100.500_tau_1.25e-05.json")
        report.append("Example: m_50.250_tau_0.0012_distribution.png")
        report.append("Example: m_200.000_tau_10.50_3d_positions.png")
        
        # è¾“å‡ºæ–‡ä»¶åˆ—è¡¨
        report.append(f"\n\nOUTPUT FILES:")
        report.append("-" * 40)
        report.append("1. llp_summary.csv - Summary statistics for all LLPs")
        report.append("2. distribution_models/ - JSON model files (named as m_{mass}_tau_{lifetime}.json)")
        report.append("3. Individual PNG files - Distribution plots (named as m_{mass}_tau_{lifetime}_{type}.png)")
        report.append("4. Comparison PNG files - Parameter space and statistical plots")
        report.append("5. analysis_summary.png - Comprehensive summary plot")
        
        # æ·»åŠ ä¸€äº›ç¤ºä¾‹æ–‡ä»¶å
        if self.distribution_models:
            report.append(f"\nExample file names:")
            for i, (llp_id, dist_model) in enumerate(list(self.distribution_models.items())[:3]):
                formatted_name = dist_model.get('formatted_name', llp_id)
                report.append(f"  {formatted_name}.json")
        
        report.append(f"\n" + "=" * 70)
        report.append("END OF REPORT")
        report.append("=" * 70)
        
        report_text = '\n'.join(report)
        
        with open(output_path / 'analysis_report.txt', 'w') as f:
            f.write(report_text)
        
        print(f"âœ“ Report saved to: {output_path}/analysis_report.txt")


def main():
    """ä¸»å‡½æ•°"""
    # è®¾ç½®è·¯å¾„
    nata = ['178', '40', 'A', 'B', 'B2', 'C', 'C2', 'D', 'D2', 'E', 'F']

    print("=" * 70)
    print("LLP DECAY POSITION DISTRIBUTION ANALYSIS")
    print("=" * 70)
    print("File naming format: m_{mass}_tau_{lifetime}")
    print("=" * 70)

    # åˆ›å»ºåˆ†æå™¨
    
    for name in nata:
        try:
            data_dir = f"/media/ubuntu/6156e08b-fdb1-4cde-964e-431f74a6078e/Files/LLP_DATA/Test/B_blocks/test_scan_{name}/llp_simulation_results/incremental_results"
            output_dir = f"/media/ubuntu/6156e08b-fdb1-4cde-964e-431f74a6078e/Files/LLP_DATA/Test/14TeV_LLP_Distribution"
            print(data_dir)
            # 1. åŠ è½½æ•°æ®
            analyzer = LLPDistributionAnalyzer(data_dir)
            print("\n[1/3] Loading data...")
            analyzer.load_all_data()
            
            # 2. åˆ†æåˆ†å¸ƒ
            print("\n[2/3] Analyzing distributions...")
            analyzer.analyze_distributions()
            
            # 3. åˆ›å»ºå¯è§†åŒ–
            print("\n[3/3] Creating visualizations...")
            # analyzer.create_distribution_plots(output_dir)
            
            # 4. ä¿å­˜ç»“æœ
            analyzer.save_results(output_dir)
            
            print("\n" + "=" * 70)
            print("ANALYSIS COMPLETED SUCCESSFULLY!")
            print("=" * 70)
            
            print(f"\nâœ… Results saved to: {output_dir}")
            print(f"\nğŸ“Š Key output files (using new naming format):")
            print(f"  {output_dir}/llp_summary.csv - Complete summary")
            print(f"  {output_dir}/distribution_models/m_{{mass}}_tau_{{lifetime}}.json - KDE models")
            print(f"  {output_dir}/m_{{mass}}_tau_{{lifetime}}_distribution.png - 2D distribution plots")
            print(f"  {output_dir}/m_{{mass}}_tau_{{lifetime}}_3d_positions.png - 3D scatter plots")
            print(f"  {output_dir}/analysis_summary.png - Comprehensive summary plot")
            print(f"  {output_dir}/analysis_report.txt - Detailed report")
            
            # æ˜¾ç¤ºä¸€äº›ç¤ºä¾‹æ–‡ä»¶å
            # if analyzer.distribution_models:
            #     print(f"\nğŸ“ Example file names:")
            #     for llp_id, dist_model in list(analyzer.distribution_models.items())[:3]:
            #         formatted_name = dist_model.get('formatted_name', llp_id)
            #         print(f"  â€¢ {formatted_name}.json")
            #         print(f"  â€¢ {formatted_name}_distribution.png")
            #         print(f"  â€¢ {formatted_name}_3d_positions.png")
            
        except Exception as e:
            print(f"\nâŒ Error during analysis: {e}")
            import traceback
            traceback.print_exc()


if __name__ == "__main__":
    main()