import numpy as np
import pandas as pd
import json
from pathlib import Path
from typing import Dict, List, Tuple, Optional
import matplotlib.pyplot as plt
from scipy import stats
from tqdm import tqdm
import warnings
warnings.filterwarnings('ignore')

class LLPProbabilityCalculator:
    """
    è®¡ç®—LLPåœ¨æŒ‡å®šç«‹æ–¹ä½“åŒºåŸŸå†…è¡°å˜çš„æ¦‚ç‡
    è¯»å–ä¹‹å‰ç”Ÿæˆçš„åˆ†å¸ƒæ¨¡å‹æ–‡ä»¶
    """
    
    def __init__(self, models_dir: str):
        """
        åˆå§‹åŒ–æ¦‚ç‡è®¡ç®—å™¨
        
        å‚æ•°:
        - models_dir: åŒ…å«KDEæ¨¡å‹JSONæ–‡ä»¶çš„ç›®å½•
        """
        self.models_dir = Path(models_dir)
        self.models = {}
        self.probabilities = []
        
    def load_all_models(self):
        """åŠ è½½æ‰€æœ‰åˆ†å¸ƒæ¨¡å‹"""
        print("=" * 70)
        print("LOADING LLP DISTRIBUTION MODELS")
        print("=" * 70)
        
        # æŸ¥æ‰¾æ‰€æœ‰JSONæ¨¡å‹æ–‡ä»¶
        json_files = list(self.models_dir.glob("*.json"))
        print(f"Found {len(json_files)} model files")
        
        if not json_files:
            # å°è¯•åœ¨å­ç›®å½•ä¸­æŸ¥æ‰¾
            models_subdir = self.models_dir / "distribution_models"
            if models_subdir.exists():
                json_files = list(models_subdir.glob("*.json"))
                print(f"Found {len(json_files)} model files in subdirectory")
        
        for json_file in tqdm(json_files, desc="Loading models"):
            try:
                model = self._load_model_file(json_file)
                if model:
                    model_id = model.get('formatted_name', json_file.stem)
                    self.models[model_id] = model
            except Exception as e:
                print(f"\nWarning: Failed to load {json_file.name}: {e}")
        
        if not self.models:
            raise ValueError("No models loaded!")
        
        print(f"\nSuccessfully loaded {len(self.models)} distribution models")
        
        # æ˜¾ç¤ºä¸€äº›ç¤ºä¾‹æ¨¡å‹
        print(f"\nFirst 3 models:")
        for model_id, model in list(self.models.items())[:3]:
            params = model['params']
            print(f"  {model_id}: m={params.get('mass', 'N/A'):.3f}GeV, "
                  f"Ï„={params.get('lifetime', 'N/A'):.2e}mm")
    
    def _load_model_file(self, json_file: Path) -> Optional[Dict]:
        """åŠ è½½å•ä¸ªæ¨¡å‹æ–‡ä»¶"""
        with open(json_file, 'r') as f:
            data = json.load(f)
        
        # æ£€æŸ¥æ•°æ®å®Œæ•´æ€§
        if 'model_stats' not in data or 'params' not in data:
            print(f"Warning: Incomplete model file {json_file.name}")
            return None
        
        # ä»æ–‡ä»¶åè·å–æ ¼å¼åŒ–åç§°ï¼ˆå¦‚æœæ•°æ®ä¸­æ²¡æœ‰ï¼‰
        if 'formatted_name' not in data:
            data['formatted_name'] = json_file.stem
        
        return data
    
    def calculate_probabilities_in_region(self, 
                                         x_range: Tuple[float, float],
                                         y_range: Tuple[float, float], 
                                         z_range: Tuple[float, float],
                                         method: str = 'monte_carlo',
                                         n_samples: int = 100000):
        """
        è®¡ç®—æ‰€æœ‰æ¨¡å‹åœ¨æŒ‡å®šç«‹æ–¹ä½“åŒºåŸŸå†…çš„è¡°å˜æ¦‚ç‡
        
        å‚æ•°:
        - x_range: Xè½´èŒƒå›´ (min, max)
        - y_range: Yè½´èŒƒå›´ (min, max)
        - z_range: Zè½´èŒƒå›´ (min, max)
        - method: è®¡ç®—æ–¹æ³• ('monte_carlo' æˆ– 'integral')
        - n_samples: è’™ç‰¹å¡æ´›æ–¹æ³•é‡‡æ ·æ•°
        """
        print(f"\n{'='*70}")
        print("CALCULATING DECAY PROBABILITIES")
        print('='*70)
        print(f"Region: X={x_range}, Y={y_range}, Z={z_range}")
        print(f"Method: {method}")
        print(f"Number of models: {len(self.models)}")
        print('='*70)
        
        self.probabilities = []
        
        for model_id, model in tqdm(self.models.items(), desc="Calculating probabilities"):
            try:
                probability = self._calculate_single_probability(
                    model, x_range, y_range, z_range, method, n_samples
                )
                
                params = model['params']
                
                result = {
                    'model_id': model_id,
                    'formatted_name': model.get('formatted_name', model_id),
                    'mass': float(params.get('mass', np.nan)),
                    'lifetime': float(params.get('lifetime', np.nan)),
                    'tanb': float(params.get('tanb', np.nan)),
                    'vis_br': float(params.get('vis_br', np.nan)),
                    'probability': probability,
                    'x_min': x_range[0],
                    'x_max': x_range[1],
                    'y_min': y_range[0],
                    'y_max': y_range[1],
                    'z_min': z_range[0],
                    'z_max': z_range[1],
                    'calculation_method': method,
                    'possibility': probability,  # æ·»åŠ è¿™ä¸€è¡Œï¼Œä¿æŒå…¼å®¹æ€§
                }
                
                self.probabilities.append(result)
                
            except Exception as e:
                print(f"\nWarning: Failed to calculate probability for {model_id}: {e}")
        
        print(f"\nâœ“ Successfully calculated probabilities for {len(self.probabilities)} models")
    
    def _calculate_single_probability(self, 
                                     model: Dict,
                                     x_range: Tuple[float, float],
                                     y_range: Tuple[float, float],
                                     z_range: Tuple[float, float],
                                     method: str,
                                     n_samples: int) -> float:
        """
        è®¡ç®—å•ä¸ªæ¨¡å‹åœ¨æŒ‡å®šåŒºåŸŸå†…çš„æ¦‚ç‡
        
        æ³¨æ„ï¼šç”±äºåŸå§‹KDEå¯¹è±¡æ²¡æœ‰ä¿å­˜ï¼Œæˆ‘ä»¬åªèƒ½ä½¿ç”¨ä¿å­˜çš„ç»Ÿè®¡ä¿¡æ¯è¿›è¡Œè¿‘ä¼¼è®¡ç®—
        è¿™é‡Œå‡è®¾åˆ†å¸ƒæ˜¯ç‹¬ç«‹çš„é«˜æ–¯åˆ†å¸ƒ
        """
        model_stats = model['model_stats']
        
        if method == 'integral':
            # ä½¿ç”¨ç§¯åˆ†æ–¹æ³•ï¼ˆå‡è®¾å„åæ ‡ç‹¬ç«‹ï¼‰
            prob_x = self._gaussian_probability_in_range(
                model_stats['x']['mean'], 
                model_stats['x']['std'], 
                x_range
            )
            
            prob_y = self._gaussian_probability_in_range(
                model_stats['y']['mean'], 
                model_stats['y']['std'], 
                y_range
            )
            
            prob_z = self._gaussian_probability_in_range(
                model_stats['z']['mean'], 
                model_stats['z']['std'], 
                z_range
            )
            
            # å‡è®¾ç‹¬ç«‹ï¼Œè”åˆæ¦‚ç‡ = P(x) * P(y) * P(z)
            probability = prob_x * prob_y * prob_z
            
        elif method == 'monte_carlo':
            # ä½¿ç”¨è’™ç‰¹å¡æ´›æ–¹æ³•
            probability = self._monte_carlo_probability(
                model_stats, x_range, y_range, z_range, n_samples
            )
        
        else:
            raise ValueError(f"Unknown method: {method}")
        
        return probability
    
    def _gaussian_probability_in_range(self, 
                                      mean: float, 
                                      std: float, 
                                      value_range: Tuple[float, float]) -> float:
        """è®¡ç®—é«˜æ–¯åˆ†å¸ƒåœ¨æŒ‡å®šèŒƒå›´å†…çš„æ¦‚ç‡"""
        if std <= 0:
            # å¦‚æœæ ‡å‡†å·®ä¸º0æˆ–è´Ÿï¼Œæ£€æŸ¥å‡å€¼æ˜¯å¦åœ¨èŒƒå›´å†…
            return 1.0 if value_range[0] <= mean <= value_range[1] else 0.0
        
        # ä½¿ç”¨scipyçš„norm.cdfè®¡ç®—ç´¯ç§¯æ¦‚ç‡
        prob_lower = stats.norm.cdf(value_range[0], loc=mean, scale=std)
        prob_upper = stats.norm.cdf(value_range[1], loc=mean, scale=std)
        
        return max(0.0, prob_upper - prob_lower)
    
    def _monte_carlo_probability(self,
                                model_stats: Dict,
                                x_range: Tuple[float, float],
                                y_range: Tuple[float, float],
                                z_range: Tuple[float, float],
                                n_samples: int) -> float:
        """ä½¿ç”¨è’™ç‰¹å¡æ´›æ–¹æ³•ä¼°è®¡æ¦‚ç‡"""
        # ä»é«˜æ–¯åˆ†å¸ƒä¸­é‡‡æ ·
        x_samples = np.random.normal(
            model_stats['x']['mean'],
            model_stats['x']['std'],
            n_samples
        )
        
        y_samples = np.random.normal(
            model_stats['y']['mean'],
            model_stats['y']['std'],
            n_samples
        )
        
        z_samples = np.random.normal(
            model_stats['z']['mean'],
            model_stats['z']['std'],
            n_samples
        )
        
        # æ£€æŸ¥å“ªäº›ç‚¹åœ¨åŒºåŸŸå†…
        in_region = (
            (x_samples >= x_range[0]) & (x_samples <= x_range[1]) &
            (y_samples >= y_range[0]) & (y_samples <= y_range[1]) &
            (z_samples >= z_range[0]) & (z_samples <= z_range[1])
        )
        
        # è®¡ç®—æ¦‚ç‡
        probability = np.mean(in_region)
        
        return float(probability)
    
    def save_probabilities(self, 
                          output_file: str = 'llp_probabilities.csv',
                          simple_format: bool = True):
        """
        ä¿å­˜æ¦‚ç‡è®¡ç®—ç»“æœ
        
        å‚æ•°:
        - output_file: è¾“å‡ºCSVæ–‡ä»¶å
        - simple_format: æ˜¯å¦ä½¿ç”¨ç®€åŒ–æ ¼å¼ (m, ltime, possibility)
        """
        if not self.probabilities:
            print("No probabilities calculated yet!")
            return
        
        output_path = Path(output_file)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        if simple_format:
            # ç®€åŒ–æ ¼å¼: m, ltime, possibility
            simple_data = []
            for prob in self.probabilities:
                simple_data.append({
                    'm': prob['mass'],
                    'ltime': prob['lifetime'],
                    'possibility': prob['probability']
                })
            
            df = pd.DataFrame(simple_data)
            # æŒ‰è´¨é‡æ’åº
            df = df.sort_values(['m', 'ltime'])
            
            print(f"\nSaving simplified CSV: m, ltime, possibility")
            print(f"Total entries: {len(df)}")
            
        else:
            # å®Œæ•´æ ¼å¼
            df = pd.DataFrame(self.probabilities)
            df = df.sort_values(['mass', 'lifetime'])
            
            print(f"\nSaving detailed CSV with {len(df.columns)} columns")
        
        # ä¿å­˜åˆ°CSV
        df.to_csv(output_path, index=False)
        
        print(f"âœ“ Probabilities saved to: {output_path}")
        
        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        print(f"\nProbability Statistics:")
        print("-" * 40)
        print(f"Mean probability: {df['possibility'].mean():.6f}")
        print(f"Min probability:  {df['possibility'].min():.6f}")
        print(f"Max probability:  {df['possibility'].max():.6f}")
        print(f"Median probability: {df['possibility'].median():.6f}")
        
        return df
    
    def create_probability_plots(self, 
                                output_dir: str = './probability_plots'):
        """åˆ›å»ºæ¦‚ç‡å¯è§†åŒ–å›¾"""
        if not self.probabilities:
            print("No probabilities calculated yet!")
            return
        
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        
        print(f"\nCreating probability plots in {output_path}...")
        
        # è½¬æ¢ä¸ºDataFrameä»¥ä¾¿ç»˜å›¾
        df = pd.DataFrame(self.probabilities)
        
        # 1. æ¦‚ç‡éšå‚æ•°å˜åŒ–çš„çƒ­å›¾
        self._create_probability_heatmap(df, output_path)
        
        # 2. æ¦‚ç‡åˆ†å¸ƒç›´æ–¹å›¾
        self._create_probability_histogram(df, output_path)
        
        # 3. æ¦‚ç‡ä¸å‚æ•°çš„æ•£ç‚¹å›¾
        self._create_probability_scatter_plots(df, output_path)
        
        print(f"\nâœ“ All probability plots saved to {output_path}")
    
    def _create_probability_heatmap(self, df: pd.DataFrame, output_path: Path):
        """åˆ›å»ºæ¦‚ç‡çƒ­å›¾"""
        fig, axes = plt.subplots(1, 2, figsize=(15, 6))
        
        # åˆ›å»ºé€è§†è¡¨
        try:
            # å°è¯•åˆ›å»ºè´¨é‡-å¯¿å‘½ç½‘æ ¼
            pivot_table = df.pivot_table(
                values='probability',
                index=pd.cut(df['mass'], bins=10),
                columns=pd.cut(np.log10(df['lifetime']), bins=10),
                aggfunc='mean'
            )
            
            # çƒ­å›¾1: åŸå§‹æ¦‚ç‡
            im1 = axes[0].imshow(pivot_table.values, cmap='viridis', aspect='auto')
            axes[0].set_xlabel('log10(Lifetime) bins', fontsize=11)
            axes[0].set_ylabel('Mass bins', fontsize=11)
            axes[0].set_title('Probability Heatmap', fontsize=12)
            plt.colorbar(im1, ax=axes[0], label='Probability')
            
            # çƒ­å›¾2: å¯¹æ•°æ¦‚ç‡
            pivot_table_log = np.log10(pivot_table.values + 1e-10)
            im2 = axes[1].imshow(pivot_table_log, cmap='plasma', aspect='auto')
            axes[1].set_xlabel('log10(Lifetime) bins', fontsize=11)
            axes[1].set_ylabel('Mass bins', fontsize=11)
            axes[1].set_title('log10(Probability) Heatmap', fontsize=12)
            plt.colorbar(im2, ax=axes[1], label='log10(Probability)')
            
        except Exception as e:
            print(f"Warning: Could not create heatmap: {e}")
            axes[0].text(0.5, 0.5, "Insufficient data\nfor heatmap",
                        ha='center', va='center', transform=axes[0].transAxes)
            axes[1].text(0.5, 0.5, "Insufficient data\nfor heatmap",
                        ha='center', va='center', transform=axes[1].transAxes)
        
        plt.tight_layout()
        plt.savefig(output_path / 'probability_heatmap.png', dpi=150, bbox_inches='tight')
        plt.close()
    
    def _create_probability_histogram(self, df: pd.DataFrame, output_path: Path):
        """åˆ›å»ºæ¦‚ç‡åˆ†å¸ƒç›´æ–¹å›¾"""
        fig, axes = plt.subplots(2, 2, figsize=(12, 10))
        
        # æ•´ä½“æ¦‚ç‡åˆ†å¸ƒ
        axes[0, 0].hist(df['probability'], bins=30, alpha=0.7, edgecolor='black')
        axes[0, 0].set_xlabel('Probability', fontsize=11)
        axes[0, 0].set_ylabel('Frequency', fontsize=11)
        axes[0, 0].set_title('Probability Distribution', fontsize=12)
        axes[0, 0].grid(True, alpha=0.3)
        
        # å¯¹æ•°æ¦‚ç‡åˆ†å¸ƒ
        log_prob = np.log10(df['probability'] + 1e-10)
        axes[0, 1].hist(log_prob, bins=30, alpha=0.7, edgecolor='black')
        axes[0, 1].set_xlabel('log10(Probability)', fontsize=11)
        axes[0, 1].set_ylabel('Frequency', fontsize=11)
        axes[0, 1].set_title('Log Probability Distribution', fontsize=12)
        axes[0, 1].grid(True, alpha=0.3)
        
        # æ¦‚ç‡ä¸è´¨é‡çš„å…³ç³»
        axes[1, 0].scatter(df['mass'], df['probability'], alpha=0.6, s=20)
        axes[1, 0].set_xlabel('Mass (GeV)', fontsize=11)
        axes[1, 0].set_ylabel('Probability', fontsize=11)
        axes[1, 0].set_title('Probability vs Mass', fontsize=12)
        axes[1, 0].grid(True, alpha=0.3)
        
        # æ¦‚ç‡ä¸å¯¿å‘½çš„å…³ç³»
        axes[1, 1].scatter(np.log10(df['lifetime']), df['probability'], alpha=0.6, s=20)
        axes[1, 1].set_xlabel('log10(Lifetime) (mm)', fontsize=11)
        axes[1, 1].set_ylabel('Probability', fontsize=11)
        axes[1, 1].set_title('Probability vs Lifetime', fontsize=12)
        axes[1, 1].grid(True, alpha=0.3)
        
        plt.suptitle('Probability Analysis', fontsize=14, y=1.02)
        plt.tight_layout()
        plt.savefig(output_path / 'probability_distribution.png', dpi=150, bbox_inches='tight')
        plt.close()
    
    def _create_probability_scatter_plots(self, df: pd.DataFrame, output_path: Path):
        """åˆ›å»ºæ¦‚ç‡æ•£ç‚¹å›¾"""
        fig = plt.figure(figsize=(14, 10))
        
        # åˆ›å»º3Dæ•£ç‚¹å›¾
        ax = fig.add_subplot(111, projection='3d')
        
        scatter = ax.scatter(df['mass'], 
                            np.log10(df['lifetime']), 
                            df['probability'],
                            c=df['probability'], 
                            cmap='viridis',
                            s=50,
                            alpha=0.7)
        
        ax.set_xlabel('Mass (GeV)', fontsize=11, labelpad=10)
        ax.set_ylabel('log10(Lifetime) (mm)', fontsize=11, labelpad=10)
        ax.set_zlabel('Probability', fontsize=11, labelpad=10)
        ax.set_title('3D Probability Scatter Plot', fontsize=12, pad=20)
        
        plt.colorbar(scatter, ax=ax, label='Probability', pad=0.1)
        
        plt.tight_layout()
        plt.savefig(output_path / 'probability_3d_scatter.png', dpi=150, bbox_inches='tight')
        plt.close()
    
    def generate_report(self, 
                       x_range: Tuple[float, float],
                       y_range: Tuple[float, float],
                       z_range: Tuple[float, float],
                       output_dir: str = './probability_results'):
        """ç”Ÿæˆæ¦‚ç‡åˆ†ææŠ¥å‘Š"""
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        
        if not self.probabilities:
            print("No probabilities calculated yet!")
            return
        
        df = pd.DataFrame(self.probabilities)
        
        report = []
        report.append("=" * 70)
        report.append("LLP DECAY PROBABILITY ANALYSIS REPORT")
        report.append("=" * 70)
        report.append(f"\nAnalysis Date: {pd.Timestamp.now()}")
        report.append(f"Number of models analyzed: {len(self.probabilities)}")
        
        report.append(f"\nREGION DEFINITION:")
        report.append("-" * 40)
        report.append(f"X range: [{x_range[0]}, {x_range[1]}] mm")
        report.append(f"Y range: [{y_range[0]}, {y_range[1]}] mm")
        report.append(f"Z range: [{z_range[0]}, {z_range[1]}] mm")
        report.append(f"Volume: {(x_range[1]-x_range[0]) * (y_range[1]-y_range[0]) * (z_range[1]-z_range[0]):.2f} mmÂ³")
        
        report.append(f"\nPROBABILITY STATISTICS:")
        report.append("-" * 40)
        report.append(f"Mean probability: {df['probability'].mean():.6f}")
        report.append(f"Minimum probability: {df['probability'].min():.6f}")
        report.append(f"Maximum probability: {df['probability'].max():.6f}")
        report.append(f"Median probability: {df['probability'].median():.6f}")
        report.append(f"Standard deviation: {df['probability'].std():.6f}")
        
        # é«˜æ¦‚ç‡æ¨¡å‹
        high_prob_threshold = df['probability'].quantile(0.9)
        high_prob_models = df[df['probability'] >= high_prob_threshold]
        
        report.append(f"\nHIGH PROBABILITY MODELS (top 10%):")
        report.append("-" * 40)
        if len(high_prob_models) > 0:
            for i, row in high_prob_models.nlargest(10, 'probability').iterrows():
                report.append(f"{row['formatted_name']}: "
                            f"m={row['mass']:.3f}GeV, "
                            f"Ï„={row['lifetime']:.2e}mm, "
                            f"P={row['probability']:.6f}")
        else:
            report.append("No models with high probability found.")
        
        # ä½æ¦‚ç‡æ¨¡å‹
        low_prob_threshold = df['probability'].quantile(0.1)
        low_prob_models = df[df['probability'] <= low_prob_threshold]
        
        report.append(f"\nLOW PROBABILITY MODELS (bottom 10%):")
        report.append("-" * 40)
        if len(low_prob_models) > 0:
            for i, row in low_prob_models.nsmallest(10, 'probability').iterrows():
                report.append(f"{row['formatted_name']}: "
                            f"m={row['mass']:.3f}GeV, "
                            f"Ï„={row['lifetime']:.2e}mm, "
                            f"P={row['probability']:.6f}")
        else:
            report.append("No models with low probability found.")
        
        # å‚æ•°ç›¸å…³æ€§
        report.append(f"\nPARAMETER CORRELATIONS WITH PROBABILITY:")
        report.append("-" * 40)
        
        try:
            # è®¡ç®—ç›¸å…³ç³»æ•°
            corr_with_mass = df['mass'].corr(df['probability'])
            corr_with_log_lifetime = np.log10(df['lifetime']).corr(df['probability'])
            corr_with_tanb = df['tanb'].corr(df['probability']) if 'tanb' in df.columns else np.nan
            
            report.append(f"Correlation with mass: {corr_with_mass:.3f}")
            report.append(f"Correlation with log10(lifetime): {corr_with_log_lifetime:.3f}")
            if not np.isnan(corr_with_tanb):
                report.append(f"Correlation with tanÎ²: {corr_with_tanb:.3f}")
        except:
            report.append("Could not calculate correlations.")
        
        report.append(f"\nOUTPUT FILES:")
        report.append("-" * 40)
        report.append("1. llp_probabilities.csv - Main results (m, ltime, possibility)")
        report.append("2. llp_probabilities_detailed.csv - Detailed results with all columns")
        report.append("3. Probability plots in ./probability_plots/")
        report.append("4. This report file")
        
        report.append(f"\n" + "=" * 70)
        report.append("END OF REPORT")
        report.append("=" * 70)
        
        report_text = '\n'.join(report)
        
        report_file = output_path / 'probability_analysis_report.txt'
        with open(report_file, 'w') as f:
            f.write(report_text)
        
        print(f"âœ“ Report saved to: {report_file}")


def main(Detector = 'CODEX-b'):
    """ä¸»å‡½æ•° - è®¡ç®—LLPåœ¨æŒ‡å®šåŒºåŸŸå†…çš„è¡°å˜æ¦‚ç‡"""
    
    # è®¾ç½®è·¯å¾„
    models_dir = "/media/ubuntu/6156e08b-fdb1-4cde-964e-431f74a6078e/Files/LLP_DATA/Test/14TeV_LLP_Distribution/distribution_models"
    output_dir = "/media/ubuntu/6156e08b-fdb1-4cde-964e-431f74a6078e/Files/LLP_DATA/Test/14TeV_LLP_Distribution/"
    
    # å®šä¹‰æ„Ÿå…´è¶£çš„åŒºåŸŸï¼ˆå•ä½ï¼šmmï¼‰
    # å¯ä»¥æ ¹æ®ä½ çš„æ¢æµ‹å™¨å‡ ä½•æˆ–æ„Ÿå…´è¶£çš„åŒºåŸŸæ¥è®¾ç½®
    x_range = (-100000, 100000)    # Xæ–¹å‘èŒƒå›´
    y_range = (100000, 125000)    # Yæ–¹å‘èŒƒå›´
    z_range = (100000, 300000)       # Zæ–¹å‘èŒƒå›´
    
    print("=" * 70)
    print("LLP DECAY PROBABILITY CALCULATOR")
    print("=" * 70)
    print(f"Target Region: X={x_range}, Y={y_range}, Z={z_range}")
    print("=" * 70)
    
    # åˆ›å»ºæ¦‚ç‡è®¡ç®—å™¨
    calculator = LLPProbabilityCalculator(models_dir)
    
    try:
        # 1. åŠ è½½æ¨¡å‹
        print("\n[1/3] Loading distribution models...")
        calculator.load_all_models()
        
        # 2. è®¡ç®—æ¦‚ç‡
        print("\n[2/3] Calculating decay probabilities...")
        calculator.calculate_probabilities_in_region(
            x_range=x_range,
            y_range=y_range,
            z_range=z_range,
            method='monte_carlo',  # ä½¿ç”¨è’™ç‰¹å¡æ´›æ–¹æ³•
            n_samples=1000000       # é‡‡æ ·æ•°
        )
        
        # 3. ä¿å­˜ç»“æœï¼ˆç®€åŒ–æ ¼å¼ï¼‰
        print("\n[3/3] Saving results...")
        
        # ä¿å­˜ç®€åŒ–æ ¼å¼CSV
        simple_csv = Path(output_dir) / f"{Detector}.csv"
        df_simple = calculator.save_probabilities(
            output_file=str(simple_csv),
            simple_format=True
        )
        
        # ä¿å­˜è¯¦ç»†æ ¼å¼CSV
        detailed_csv = Path(output_dir) / f"{Detector}_detailed.csv"
        calculator.save_probabilities(
            output_file=str(detailed_csv),
            simple_format=False
        )
        
        # 4. åˆ›å»ºå¯è§†åŒ–
        print("\n[4/3] Creating visualizations...")
        calculator.create_probability_plots(output_dir)
        
        # 5. ç”ŸæˆæŠ¥å‘Š
        calculator.generate_report(
            x_range=x_range,
            y_range=y_range,
            z_range=z_range,
            output_dir=output_dir
        )
        
        print("\n" + "=" * 70)
        print("PROBABILITY CALCULATION COMPLETED!")
        print("=" * 70)
        
        print(f"\nâœ… Results saved to: {output_dir}")
        print(f"\nğŸ“Š Main output files:")
        print(f"  {simple_csv} - Simplified CSV (m, ltime, possibility)")
        print(f"  {detailed_csv} - Detailed CSV with all information")
        print(f"  {output_dir}/probability_plots/ - Visualization plots")
        print(f"  {output_dir}/probability_analysis_report.txt - Analysis report")
        
        # æ˜¾ç¤ºä¸€äº›ç¤ºä¾‹ç»“æœ
        if df_simple is not None and not df_simple.empty:
            print(f"\nğŸ“ˆ Example results (first 5):")
            print("-" * 40)
            for i, row in df_simple.head().iterrows():
                print(f"m={row['m']:.3f}GeV, "
                      f"Ï„={row['ltime']:.2e}mm, "
                      f"P={row['possibility']:.6f}")
        
    except Exception as e:
        print(f"\nâŒ Error during probability calculation: {e}")
        import traceback
        traceback.print_exc()


def batch_calculate_probabilities():
    """
    æ‰¹é‡è®¡ç®—å¤šä¸ªä¸åŒåŒºåŸŸçš„æ¦‚ç‡
    å¯ä»¥ç”¨äºç³»ç»Ÿç ”ç©¶ä¸åŒå‡ ä½•åŒºåŸŸ
    """
    models_dir = "/media/ubuntu/6156e08b-fdb1-4cde-964e-431f74a6078e/Files/LLP_DATA/Test/B_blocks/test_scan_F/distributution_density"
    base_output_dir = "/media/ubuntu/6156e08b-fdb1-4cde-964e-431f74a6078e/Files/LLP_DATA/Test/B_blocks/test_scan_F"
    
    # å®šä¹‰å¤šä¸ªæ„Ÿå…´è¶£çš„åŒºåŸŸ
    regions = {
        'region_small': {
            'x_range': (-50, 50),
            'y_range': (-50, 50),
            'z_range': (0, 100),
            'description': 'Small central region'
        },
        'region_medium': {
            'x_range': (-100, 100),
            'y_range': (-100, 100),
            'z_range': (0, 200),
            'description': 'Medium central region'
        },
        'region_large': {
            'x_range': (-200, 200),
            'y_range': (-200, 200),
            'z_range': (0, 400),
            'description': 'Large central region'
        },
        'region_forward': {
            'x_range': (-50, 50),
            'y_range': (-50, 50),
            'z_range': (200, 400),
            'description': 'Forward region'
        }
    }
    
    print("=" * 70)
    print("BATCH PROBABILITY CALCULATION")
    print("=" * 70)
    
    # åŠ è½½æ¨¡å‹ä¸€æ¬¡ï¼Œé‡å¤ä½¿ç”¨
    calculator = LLPProbabilityCalculator(models_dir)
    calculator.load_all_models()
    
    all_results = []
    
    for region_name, region_config in regions.items():
        print(f"\nğŸ“ Calculating for region: {region_config['description']}")
        
        output_dir = Path(base_output_dir) / "probability_results" / region_name
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # è®¡ç®—æ¦‚ç‡
        calculator.calculate_probabilities_in_region(
            x_range=region_config['x_range'],
            y_range=region_config['y_range'],
            z_range=region_config['z_range'],
            method='monte_carlo',
            n_samples=100000
        )
        
        # ä¿å­˜ç»“æœ
        csv_file = output_dir / "llp_probabilities.csv"
        df = calculator.save_probabilities(
            output_file=str(csv_file),
            simple_format=True
        )
        
        # æ·»åŠ åŒºåŸŸä¿¡æ¯
        df['region'] = region_name
        df['region_description'] = region_config['description']
        
        all_results.append(df)
        
        print(f"âœ“ Results saved to: {csv_file}")
    
    # åˆå¹¶æ‰€æœ‰ç»“æœ
    if all_results:
        combined_df = pd.concat(all_results, ignore_index=True)
        combined_file = Path(base_output_dir) / "probability_results" / "all_regions_combined.csv"
        combined_df.to_csv(combined_file, index=False)
        
        print(f"\nâœ… All results combined and saved to: {combined_file}")
        print(f"Total entries: {len(combined_df)}")
    
    print("\n" + "=" * 70)
    print("BATCH CALCULATION COMPLETED!")
    print("=" * 70)


if __name__ == "__main__":
    # è¿è¡Œå•ä¸ªåŒºåŸŸè®¡ç®—
    main(Detector='MATHUSLA_test')
    
    # å¦‚æœéœ€è¦æ‰¹é‡è®¡ç®—å¤šä¸ªåŒºåŸŸï¼Œå–æ¶ˆä¸‹é¢è¡Œçš„æ³¨é‡Š
    # batch_calculate_probabilities()